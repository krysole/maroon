---- Vectors ----

let vec_1 <- vec{i64, 6}[0, 1, 2, 3, 4, 5]
let vec_2 <- vec{i64, 6}[]


---- Parametric Types ----

Most interesting types are somewhat parametric. Vectors and similar types are 
the most obvious example, but technically so are pointers.

vec{i64, 100}
vec{i64}

ptr{i64}


---- Fluorite Runtime System Calling Convention ----

The Fluorite Runtime System has to deal with two basic constraints when dealing
with message sends, and therefore method activation (calls). Those constraints
are C interopability, and effecient language feature implementation.

Interopability with C mostly just requires that we can call C, but the cost
of implementing different strategies for doing so vary significantly. The
strategy considered here is a combined stack strategy, where C and Fluorite
frames are freely intermixed and basic debugging symbols for statically 
compiled code are provided for both allowing basic backtraces and stack
inspection without additional tooling, although such tooling is expected to
allow more comprehensive analysis of Maroon and Fluorite code and data.

Some features of Fluorite prevent the use of the C ABI directly, as it is used
in Objective-C. These features are looked at briefly below, along with the
consiquence to compatability.

Tail messages allow a method to jump to the body of another message without
consuming any additional stack space. This can be extremely efficient for
some algorithms and when done explicitly, as it is in Fluorite, we can avoid
issues like inconsistent stack analysis. To ensure that we can make tail
messages as efficient as possible it is helpful to know exactly how many 
arguments we actually have so that we don't have to spill or fill all of the
registers that are used for parameters. In the AMD64T C ABI used by macOS
there are several general purpose as well as vector float registers used
for parameter passing, which would necessitate a significant amount of 
overhead for such a feature.

Multiary parameters allow an arbitrary number of strictly reference parameters
to be provided to a method. Primitive types must use specialized method
definitions directly, and cannot use generic method handlers, where multiary
parameters are a way to access generic method parameters directly in a flexible
and programatic fashion. These parameters can then be converted into a Array
or other data structure if required, or could even be peeled of one by one
while checking for the number of arguments actually provided per call.

The issue with multiary parameters is that they must be in an efficient format
since we are likely to use them somewhat more frequently than variadic functions
in C. Making them consistently stack based with a count passed by register, 
would accomplish this in a simple fashion.

The basic strategy appears to be as follows, pass parameters in a parameter
window on the stack. The stack frames are statically sized similarly to C.
The number of actual arguments is passed in a register. Basic data like the
selector information, not just the receiver, should also be passed as parameters
as they are in Objective-C. This will allow calls to perform tail messages 
correctly, as well as evaluate code conditionally on the selector without an
additional calling convention. Call-site metadata is also calculated, but it
is not reused by tail messages or any other messaging mechanism, so it can be
left in registers. There is also the closure parent object, which can just
be passed in a register also, since it is method specific.

There are also some other thread local variables that can be retained in
registers for performance and convenience. The managed frame link can be
computed and left in a register for fast access, for example. The managed
frame link points to the beginning of the Garbage Collector information for 
the frame, and is spilled into a fiber object afterwards. Respectively, the
fiber reference can also be stored in a register for convenience and fast
access. The fiber object also indicates its thread using whatever passes
on the OS in question as a thread id, but that is simply for tools or other
inspectors to interrogate as required.


---- Minimal Object System for Bootstrapping Fluorite ----

class Object () {
  
  static public [...] {                -- va parameters.
    goto allocate.initialize(...);     -- Tail message with original parameters.
  }
  
  static allocate {                    -- Note static is for class methods.
    ...
  }
  
  private public  do @public           -- Abridged notation for method decl.
  private private do @private          -- @private/@public are built in per object.
  private super   do @super            -- @super is also built in for each object.
  
  private initialize do @public        -- By default init returns @public.
  
}

class Array (Object) {
  
  let count    <- nil;                 -- Variable with ref type can be initialized
  let contents <- nil;                 -- using the nil default value.
  let tail     <- vec{4, id}[];        -- Vector types are supported over ids.
  
  public count do @count;              -- A simple accessor over instance variable.
  
  public [index] do @tail[index];      -- Remember that vectors are bounds checked.
  
  private initialize(...) {
    if va_count[] > 4 then abort[];    -- va parameters count.
    
    super.initialize                   -- @super provides the super message table.
    
    count <- va_count[];               -- count is actually the accessors for @count.
    for i in va_domain[] {             -- va_domain is interval for va parameters
      @tail[i] <- va[i];
    }
    
    return public;
  }
  
}


---- Object Layout ----

I think that object layout will follow something like the following.

struct Object {
  header_a: u64 { class: 48, size:  9, gc:         7 }
  header_b: u64 { hash:  48, flags: 6, ref_count: 10 }
  ref:      vec{ref, 0 < ref_count   < 512 } -- 512 == 1 << 10 << 3
  data:     vec{u64, 0 < (size << 4) < 256 } -- 256 == 1 <<  9 << 3
}

The calculations the GC and runtime need to do to bounds check object 
accessing are relatively simple since they're just stored directly in the first
header field. Both the size when accessing bytes, and the slot count when
calculating the data offset or when bounds checking slot accessing are directly
available.

The size is the exact number of word pairs used by the object, which has a 
limit of 256 word pairs in total. This is then bumped by one bit to indicate 
a sign bit, which can tell us whether we are dealing with a tiny object or a 
regular object. The total number of bytes has a 4KB byte limit, and it should
be noted that the size includes the header word pair.

The slot_count is the exact number of slots available, totalling a 512 slot
limit for any single object. This equals the entire 4KB object size limit. Note
that the calculating for the slot_count must take into account that the limit
is not 512, but 510, since two fields are used by the header, and are therefore
reserved and not for actual use.


---- Optimization and Deoptimization ----

Since Fluorite is currently statically compiled, deoptimization is not 
currently planned, or even really possible without a compiler provided by
the runtime system to generate the new code, and a runtime facility to load
it correctly.

The primary optimizations for dynamic languages however, are various kinds of
inline cachine of message lookups, and method inlining. Object transmutation 
should also be discussed.

The former isn't really
affected by anything we're doing and should work more or less unchanged, except
that monomorphic inline caches are not supported since code in Fluorite is
never directly writable, instead polymorphic inline cache tables are used 
instead.

Method inlining is more of a challenge though, since class changes would
require a recompile of any effected methods. This isn't simply a problem for
methods that have yet to be activated, but is also a problem for any stacks
that are currently executing offending out of date methods, that may no longer
reflect object structure or method behavior.

It probably makes sense to limit object structural change completely and limit
method replacement when inlining is turned on in the compiler, allowing 
programs that absolutely must have inlining to perform better, while also
allowing programs that require maximum flexibility to function correctly until
a dynamic optimizing and deoptimizing compiler can be written.

Lastly, object transmutation deserves a minor mention on the topic of inlining.
When a method is inlined, especially accessors, it is likely that another
objects slots or data might be read directly by a method of a different class.
This isn't really a problem directly, but if that object is transmuted, the
slots and data will no longer be tracked by the garbage collector. This
suggests that methods must be inlined between two runtime system 
synchronization points, and never accross a synchronization point.

Synchronization points are a specific kind of concurrency barriers also.


---- Named Literal Objects versus Named Literal Values ----

It occurs to me that I can't really have object literals for true and
false, as well as primitive equivalents. The problem is then, should all constants
in Maroon be capitalized. They probably should anyway, in which case
true and false could simply be consistent with that convention...

nil:   Nil
true:  Boolean
false: Boolean

TRUE:  boolean
FALSE: boolean

NULL:  ptr        -- Assuming that I have this at all...


---- Explicit versus Implicit typing ----

Parameters require explicit types, or must be references in Fluorite code, 
since they cannot have default values without the default value emitted and
passed by the caller during compilation. Return types are the same as parameters.

Conversely, variables can and must have a default value, even if that value
is just null memory. Null initializers are required for all values and would
simply be emitted by default if the code only specified the type and not the
initializer.

Given this, it makes some sense that variables are initialized and parameters
are type specified.

The only possible exception to this is that this requires that a custom 
allocate method be generated for all concrete classes, since they too would be
initialized to default values, if only null values. They can then be initialized
properly by the objects initialize method afterwards. This is relatively 
important to do in any reasonable managed runtime system to prevent memory
corruption anyway, so either default values may be specified, or the memory
must be cleared to zero.

It may be helpful in some cases for null values that are not cleared memory
to be allowed, in which case real initializers are absolutely required. The 
object initialization strategy is designed to not require this, but it may be
useful when detecting what has or has not been initialized in complex objects.


---- The Object Type vs The ref Type ----

It occurs to me that the ref type is the general catch all reference type 
for Fluorite code, similar to Objective-C, and for similar reasons. Like
Objective-C, most code will generally choose to specify Object rather than id
directly, but sometimes there isn't a particular reason to specify any actual
type directly.

The question here is whether we should expect most objects to mixin Object or
not?

If we generally expect all reasonable objects to mixin Object that behave in 
any particularly reasonable fashion, then typing to Object as the basic type
makes sense, similar to most Objective-C or Java programs. On the other hand
some code may have absolutely no interest in what object is present and that
code may use ref similar to id in Objective-C.

This suggests that figuring out whether to use ref or Object may not always
be completely trivial, but I think that its probably simple enough that it
shouldn't cause any real problems. For the most part, since all instantiable
objects mixin Object anyway, it probably doesn't actually matter.

Even proxy objects or remote objects technically mixin Object, its just done 
in a circuitous fashion. Especially with remote objects, which support all 
of the messages that you would typically expect them to, but obviously cannot
support type messages directly, so the remote object bridge must implement
type compatability to bridge class tags between the two environments in order 
to function correctly.


---- Enumeration in Maroon and Fluorite ----

Enumeration is a slightly tricky concept, most of the time in Fluorite being
done with procs, but sometimes it must be fast or when written in Maroon, must
be implemented using plain data.

To make this work, my current thinking is that something similar to Rust's
traits might work reasonably well, specifically focussing on providing a trait
for a struct that is returned by a enumerate function, or simply by directly
supporting certain built in types directly.

One example of this might be an interval trait, which could support an enumerable
trait, which in turn could suppport the enumerator trait, which then provides
the functions that implement each of the methods like init, condition, iterate.
These functions are obviously just modelled on standard enumeration in C.

Given that this is a fairly straightforward concept, my current thinking is 
that it would be useful to consider providing a interim feature that implements
the common cases directly in the compiler, until traits are implemented. This
interim feature would work on compiler recognized constructs like interval
expressions, and domain primitive calls on vectors or similar.

  for i in [0..9] {...}
  for i in domain[my_vec] {...}
  for e in my_vec

The latter avoids the issue of not having proper dot operators yet. If I can
get a proper dot operator working then the following would probably also work.

  for i in my_vec.domain {...}

The one problem I see immediately is that the above is still just a shorthand
for proper traits, and therefore also for proper enumerators. Some enumerators
therefore cannot be constructed in this way properly. For example, it should be
possible to partially evaluate even some Fluorite code by making standardized
assumptions in the compiler about the implementation of certain types. Intervals
could fit into this and that would allow for more complex intervals to be
constructed.

  for i in [0..9].step(2) {...}

This does not require construction of an Interval instance, but can instead
simply construct an Interval struct. The struct must obviously be named something
other than Interval, but since we're more or less just computing the enumerator
here, we could view this as partially evaluating enumerate, and having it return
a struct, which would then do what we're expecting.

Basically, there would be two enumerate methods, one that returns an appropriate
Enumerator class instance, and one that returns an appropriate Enumerator trait 
instance. Again the names conflict here but we can possibly deal with that by
naming one Iterator or something.

Given all of the above, the implementation would have to either be very specific
to the cases given above, or would probably have to have full support for both
some kind of namespaces to deal with the name collisions as well as some kind
of Rust like trait system. Anything less would likely not fully support all
kinds of basic enumeration behavior, and we would likely still require some
degree of real general use enumeration support anyway.

My current thinking is that we should probably support a conventional for loop
regardless of any of the above, and the benefits that proper enumerators may
bring to the table, simply because they can provide case be case support for
code that has yet to gain an Enumerator/Enumerable trait to support it.


---- Namespaces ----

I'm not yet sure if namespaces are really required for either Maroon or 
Fluorite.

In Fluorite, they don't really make sense since the object capability model is
used to separate modules from one another. All symbols are explicitly pulled
into scope using import statements at the top of a Fluorite module.

In some sense Fluorite modules may require some kind of pattern inclusion of
Maroon/C symbols to allow things like OpenGL or SDL to be quickly and
effectively pulled into scope. This would then allow those functions or types
to be referred to relatively straightforwardly, but as a rule arbitrary use
of global names would interfere with local messages, since only names that
are not in lexical scope are sent to the local private interface.

A more general prefix could be used to allow accessing the complete Maroon/C
namespace when it is required. Something like mn.glVertex3f or something.

In Maroon on the other hand, the design I'm currently considering is to use
some combination of C compatability, which will make the bridge with Fluorite
a little simpler also, combined with features like Rust's traits to facilitate
type parametricity and generic functions.

On a minor side note, I wonder if the type parametricity can be unified between
the gradual typing in Fluorite and the strictly compile time strategy required
for a Rust style trait system.


---- Pointers and Pointer Arithmetic ----

One of the interesting things about pointers in Maroon is that they are defined
notationally as a parametric type just like vectors are. This means that
while the semantics may be somewhat eccentric, the notation is quite consistant
with the other types in the system.

Remembering that the basic notation for generics and here specifically pointers
is as follows.

  let a <- i64[0]
  let p <- ptr[a]
  let x <- p[]

This could have been done with something like ref[p] instead, but that isn't
quite as consistent as an eccentric implementation of the Applicable trait.

Basic pointer arithmetic then follows this notation by allowing an index to
be provided that produces an offset equaling the index multiplied by the
element size.

  let v <- vec{i64}[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]
  let x <- p[10 - 1]

Lastly we can use these like any other location, since the pointer was 
originally a pointer anyway, we can of course compute any arithmetic back to
another pointer.

  ptr[p[10 - 1]]

The only thing I'm not yet sure about, is whether I should support a feature
that allows arithmetic directly with pointer values. For example, should it
be possible to apply the + operator over a pointer and integer.

  p <- p + (10 - 1)
  p <- (10 - 1) + p

This would theoretically work just fine, and many kinds of mathematics are not
inherently commutative when applying some operators over certain type 
combinations. This isn't really any different than addition over scaler/matrix
or scaler/vector operands in linear algebra.

For now I'm thinking that since supporting linear algebra style operations is
more or less intended at some point anyway, and type promoting operations like
this are not generally expected to follow the laws of commutativity anyway, 
we can just deal with it. The reason for this note then is partly because this, 
like linear algebra imposes a constraint on the arithmetic traits that define
the operators.

This could be implemented using a template that synthesises instances of the
infix(+) operator as required, converting the code to the built in style
automatically.

  template{T}
  inline infix(+)[a: ptr{T}, b: i64] do ptr[a[b]]

This might be preferable to trying to do some special compiler functionality, 
since we'll need some sort of operator function overloading anyway at some
point, and in fact, it may be useful to be able to define all of the built in
functions in a similar fashion, seperating out the cases in the compiler for
code generation.


---- Random Number Generation ----

This is a note that is more or less for later reference, but there are three
main forms of random number generation theory, as I understand it. Psuedo
Random Number Generation, Entropy Collection and Normalization, and Cryptographic
Theory and Practice.

The latter is probably best left up to a cryptographic library maintained by
someone who is an expert in that area, probably even just a wrapper around an
existing C library that already exists and is provided by platform vendors.

The first two however, are somewhat more interesting.

There is some somewhat interesting PRNG work called Permuted Linear Congruential
Generation, or PCG for short. This work from what I understand supercedes all
conventional fast PRNG systems while remaining uniform and generating all values.
It has the properties typically expected of a PRNG family for general use in
a high level language.

At the moment I'm not particularly familiar with the strategies for dealing with
entropy, except that most forms of entropy suffer from non uniform distribution,
meaning that they need to be normalized somewhat before being used, and they
don't necessarily produce a lot of bits in many cases, limiting how quickly
entropy can be generated.

Entropy systems usually are also based on some degree of confidentiality, 
typically by either using sources of entropy that are not easily observable
by other programs or users, or by combining so many such sources that it is
expensive to intercept or replicate all of them effectively. This would then
be combined with some degree of PRNG to increase the amount of data available, 
but some care is typically required when dealing with cryptography.

Technically there is also published random numbers or other similar books, but
they are a somewhat more complex issue, and typically are just a convenience
for sharing entropy that is pregenerated, for example when publishing a study
that uses a large amount of random numbers, but where you may not want to 
separately publish your random numbers, or you may not want to be questioned
about why those specific numbers were chosen.

I'm not currently sure what entropy or published random numbers support I'm
likely to implement yet, but I think there are two relatively obvious features
that would use a PCG system.

Firstly, the fully specified 64 bit implementation and a somewhat smaller and
potentially somewhat faster 32 bit implementation could be provided as a direct
source of PRNG, along with some notes and caveats to help programmers avoid
making obvious mistakes when using them, not treating the 32 bit generator as
half of a 64 bit generator for example.

Secondly, I think a generic version of the algorithm would be quite useful
which is matched to the bit output that is expected. That is, you could specify
properties like generating numbers exactly once, uniformity is always assumed, 
or you could even try increasing the number of permutations mixed in to increase
the number of repetitions without sacrificing uniformity. That would be useful
for some cases were the amount of numbers required is quite large, but the amount
of repetitions matters.


---- Engineering Values ----

I'm not yet exactly sure what the priorities of these are, so take them roughly
in the order that they appear. Like Rust, we wish to 'bend the curve' alot here, 
especially where the values are not mutually exclusive under better strategies.

- Software Change Stability
  Don't break compatability where possible.

- Wetware Change Stability
  Don't make people rewire their wetware continuously.
  
  Major Releases; 10 years, language design changes.
  Minor Releases; 2 years, core library additions.
  Patch Releases; immediate, security corrections.
  
  Performance is the dark horse which sometimes necessitates minor releases
  changes, despite potentially changing programmers mental models of the
  language. As a rule, these should be on major releases to reduce codebase
  churn resulting from changes in programming strategies, but changes that
  appear stable for the long term may be exceptions to the rule. My thinking
  here is that they would be allowed into minor releases, on the provision that
  they are not expected to cause churn due to optimization changes in 
  applications, or the performance improvement is very significant.


- Message Passing and Object Capabilities (Fluorite)

  A message can be implemented with a method certainly, but it is still a message, 
  and it can always just be forwarded, or programatically handled, including
  sending it over a network.
  
  Capabilities respectively are not just a way of writing modular programs, but
  should be seemless and straightforward to work with, and in some cases should
  even have resource accounting. This isn't particularly helpful for security, 
  but it helps a great deal for engineering, and could even be quite fun for
  things like game developers or user programmers possible.
  
  Capabilities may occassionally limit some Maroon functionality in Fluorite
  methods, to allow them to be instantiated non globally.

- Straightforward Design
  The notation should be straightforward but consistent.
  
  Programmers should not expect to write the shortest code possible whenever
  possible, since this doesn't always make the code simpler or less costly to
  design and maintain.
  
  Programmers likewise shouldn't be coding tornados making a mess, and the 
  language should make design and maintainence itself practical, if again, not
  alway necessarily the fastest.
  
  Put simply, the costs should be bounded, and programming should be a 
  satisfying and professional endevour.


- Performance (Maroon and Fluorite)
  Balenced latency, throughput and compactness.
  
  This is especially notable for the memory management in Fluorite, which is
  supposed to use a combination of cache oriented reference counting, along with
  a pause free garbage collector, while still compacting memory by moving 
  objects using the message passing value above to allow message forwarding
  during object relocation. An example of values coming together to solve a 
  larger problem.
  
- Systems Programming (Maroon and Fluorite)
  It is necessary to be able to leverage the capabilities of the machine and
  the operating system to write interesting programs, period.


- Secure By Default
  Security isn't a core engineering value, but not preventing it is. We 
  shoudn't break security in the name of other tradeoffs if at all possible.

- Reliability and Fault Tolerance
  Software should generally be reliable and relatively free of fault, but when
  a fault does arise, it should not generally be handled by special cases but
  by a general principle like heirarchical system restart logic.


- Function then Safety then Productivity, but only a little.
  We should be able to write what we need, do it without high risk of introducing
  faults, and without spending inordinate amounts of time doing so, in that order, 
  but all of them where ever possible.



---- macOS x86-64 Calling Convention Notes ----

  * rdx:rax is return value.
  * rdi, rsi, rdx, rcx, r8, r9 are integer parameters.
  * rbx, rsp, rbp, r12, r13, r14, r15 are preserved.
  * r10 is the static chain pointer, not used by C programs (i.e., scratch).
  * r11 is scratch.
  
  * zmm0-zmm7 are FP parameters.
  * zmm8-zmm31 are FIXME[scratch|preserved].
  * k0-k7 are FIXME[scratch|preserved].
  
  * DF in %rFLAGS must be clear on function entry and exit (direction flag should be set to forward).
  * x87 (not MMX) mode should be set on function entry and exit.
  * x87 registers are scratch and MMX cannot be set, use `femms` to switch to x87 before exit if necessary.
  * MXCSR and x87 control bits are preserved.
  * MXCSR and x87 status bits are scratch.
  
  * Stack alignment must at least 16 bytes.
  * When a 32 byte parameter is passed call stack alignment must be at least 32 bytes.
  * When a 64 byte parameter is passed call stack alignment must be at least 64 bytes.
  
  * rbp where used should point directly to preserved rbp location.
  * preserved rbp should be immediately below the return address.
  * rsp should point to the first stack location in the current frame.
  * -128(%rsp) is the 'red zone' and may be used by leaf functions instead of a proper frame.
  * al (not zero/sign extended) for vararg calls must be upper bound on SSE parameters.
  
  * _Bool, boot_t and bool (C++) are either 1 byte values 0x01 or 0x00.
  
  * Types that are smaller than an 8 byte integer are not zero/sign extended.
  
  * _Bool, bool_t and bool (C++) are passed as 8 byte integer.
  * char, short, int, long, long long and pointers are passed as 8 byte integer.
  * float, double, _Decimal32 and _Decimal64 are passed as 8 byte SSE.
  * __int128 are passed as two __int64 struct except with 16 byte alignment when passed on stack.
  
  * structs larger than 16 bytes are passed on the stack
  * small structs are passed as 8 byte chunks.
  * if a chunk contains any integers it is passed in an alu register.
  * if a chunk only contains floats or doubles it is passed in SSE.
  * two floats may need to be packed into a single SSE register.
  * multiple integers and possibly a float may need to be packed into a single ALU register.


---- DWARF Register Number Mapping ----

  |     0  %rax           |
  |     1  %rdx           |
  |     2  %rcx           |
  |     3  %rbx           |
  |     4  %rsi           |
  |     5  %rdi           |
  |     6  %rbp           |
  |     7  %rsp           |
  |  8-15  %r8-%r15       |
  |    16  return_address |
  | 17-24  %xmm0-%xmm7    |
  | 25-32  %xmm8-%xmm15   |
  | 33-40  %st0-%st7      |
  | 41-48  %mm0-%mm7      |
  |    49  %rFLAGS        |
  |    50  %es            |
  |    51  %cs            |
  |    52  %ss            |
  |    53  %ds            |
  |    54  %fs            |
  |    55  %gs            |
  | 56-57  reserved       |
  |    58  %rs.base       |
  |    59  %gs.base       |
  | 60-61  reserved       |
  |    62  %tr            |
  |    63  %ldtr          |
  |    64  %mxcsr         |
  |    65  %fcw           |
  |    66  %fsw           |


---- Note on macOS Executable Format ----

macOS uses a small executable memory layout (object) model, and doesn't require
complex handling of offset tables in current x86-64 systems, but there are
potentially some cases which might require the use of `name@GOTPCREL(%rip)`
style indirect accesses of data, where the data is considered too large to
be put into the 2GB region of an executable, and is instead put in the larger
4GB region from beginning from the GOT.

These large addresses require a proper offsets and thus all code and small 
data are stored within Â±2GB of the GOT, and large objects may be 2-4GB after
the GOT which will still be within the 4GB size limit imposed by the macOS ABI 
on executable/library memory layouts.

Also, any data element that is not defined in the current executable must be
accessed through `callq name` or `movq name@GOTPCREL(%rip), %rax; 
movq (%rax), %rax`. The former will in cases where the name is not local to 
the linked file, automatically generate a very near call into a trampoline at 
the end of the current procedure, responsible for loading the correct address 
and branching to it. Basically, both methods are effectively the same, more 
or less.


---- Order Operations in Assembly ----

In the current code configuration, I don't have any way to generate single
byte instruction operands only eight byte instruction operands. Because of
this it was easier to simply not support ordering operators.

It should be possible to implement an ordering operator similar to the
following at a assembly level:

ord_i64(rdi, rsi)  ## Parameters rdi, rsi; returning rax; scratching rdx.
  cmpq   rdi, rsi  ## These could possibly be in same registers?
  setl   al
  setg   dl
  subb   al, dl
  movzbq rax, al

The following table indicates the correlation between flags and ordering.

              Result  Less  Greater  Below  Above  Equal
Ascending          1     1        0      1      0      0
Equal              0     0        0      0      0      1
Descending        -1     0        1      0      1      0
